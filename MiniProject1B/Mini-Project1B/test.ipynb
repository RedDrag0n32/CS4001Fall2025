{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd39df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 32 # (Hz)\n",
    "GAMES = [\"boring\", \"calm\", \"horror\", \"funny\"]\n",
    "\n",
    "# Read the data\n",
    "data = []\n",
    "for game_id, game in enumerate(GAMES):\n",
    "    game_data = pd.read_csv(os.path.join(\"data\", f\"S01G{game_id + 1}AllChannels.csv\"))\n",
    "    game_data[\"game\"] = game\n",
    "    data.append(game_data)\n",
    "\n",
    "data = pd.concat(data, axis = 0, ignore_index = True)\n",
    "\n",
    "data.head()\n",
    "\n",
    "# TODO: choose one of the frontal (F3 / F4 / F7 / F8 / FC5 / FC6) or temporal (T7 / T8) electrodes and ensure the signal is clean\n",
    "electrode = \"T7\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for game in GAMES:\n",
    "    ax.plot(data[data[\"game\"] == game][electrode], label = game)\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_xticks(range(0, len(data), SAMPLE_RATE * 60 * 10))\n",
    "ax.set_ylabel(\"mV\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "data = data[[electrode, \"game\"]]\n",
    "data.head()\n",
    "\n",
    "# TODO: adjust if needed\n",
    "clip_length = 2 # (seconds)\n",
    "\n",
    "# Split into clips\n",
    "clipped_data = []\n",
    "y = []\n",
    "for game_id, game in enumerate(GAMES):\n",
    "    clips = np.array_split(\n",
    "        data[data['game'] == game][electrode].to_numpy(), \n",
    "        len(data[data['game'] == game]) // (clip_length * SAMPLE_RATE))\n",
    "    clipped_data.extend(clips)\n",
    "    y.extend([game_id] * len(clips))\n",
    "\n",
    "# Remove edge effects\n",
    "min_length = np.min([len(arr) for arr in clipped_data])\n",
    "X = []\n",
    "for array in clipped_data:\n",
    "    X.append(array[:min_length])\n",
    "\n",
    "X = np.vstack(X, dtype = float)\n",
    "y = np.array(y, dtype = int)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Add an additional axis required by torch's Conv layers\n",
    "X = np.expand_dims(X, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train, X_test = torch.Tensor(X_train), torch.Tensor(X_test)\n",
    "y_train, y_test = torch.Tensor(y_train), torch.Tensor(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "class LFPDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Batch generators\n",
    "\n",
    "# TODO: adjust if needed\n",
    "batch_size = 32\n",
    "\n",
    "train_batch_generator = torch.utils.data.DataLoader(LFPDataset(X_train, y_train), batch_size = batch_size,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "test_batch_generator = torch.utils.data.DataLoader(LFPDataset(X_test, y_test), batch_size = batch_size,\n",
    "                                                    shuffle = False)\n",
    "\n",
    "\n",
    "# TODO: adjust if needed\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv1d(1, 1, kernel_size = 4, padding = \"same\"),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv1d(1, 1, kernel_size = 4, padding = \"same\"),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64, 4),\n",
    "    torch.nn.LogSoftmax(dim = 1)\n",
    ")\n",
    "\n",
    "def train(n_epoch, model):\n",
    "    # TODO: adjust learning rate if needed\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "    for e in range(n_epoch):\n",
    "        model.train(True)\n",
    "\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        for X_batch, y_batch in train_batch_generator:\n",
    "            model.zero_grad()\n",
    "            logits = model(X_batch).squeeze()\n",
    "            loss = torch.nn.functional.nll_loss(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.detach().numpy())\n",
    "            \n",
    "            prediction = torch.softmax(logits, dim = 1).detach().numpy()\n",
    "            prediction = np.argmax(prediction, axis = 1)\n",
    "            train_acc.append(accuracy_score(y_batch.detach().numpy(), prediction))\n",
    "\n",
    "        model.train(False)\n",
    "        test_loss = []\n",
    "        test_acc = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_batch_generator:\n",
    "                logits = model(X_batch).squeeze()\n",
    "                loss = torch.nn.functional.nll_loss(logits, y_batch)\n",
    "                test_loss.append(loss.detach().numpy())\n",
    "\n",
    "                prediction = torch.softmax(logits, dim = 1).detach().numpy()\n",
    "                prediction = np.argmax(prediction, axis = 1)\n",
    "                test_acc.append(accuracy_score(y_batch.detach().numpy(), prediction))\n",
    "\n",
    "        print(f\"Epoch {e} : train_loss={np.mean(train_loss)}, train_acc={np.mean(train_acc)}, test_loss={np.mean(test_loss)}, test_acc={np.mean(test_acc)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "    train(n_epoch = 100, model = model)\n",
    "\n",
    "    a_clip = X[0]\n",
    "plt.plot(a_clip.flatten())\n",
    "\n",
    "prediction = model(torch.tensor(np.expand_dims(a_clip, 1)).float())\n",
    "prediction = torch.softmax(prediction, dim = 1).detach().numpy()\n",
    "prediction = int(np.argmax(prediction, axis = 1)[0])\n",
    "\n",
    "GAMES[prediction]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
